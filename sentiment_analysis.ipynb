{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Customer Reviews\n",
    "\n",
    "This notebook performs sentiment analysis on customer reviews using TF-IDF vectorization and Logistic Regression. We will preprocess the text data, train a model, and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "First, we import the necessary libraries for data processing, vectorization, modeling, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sample Dataset\n",
    "\n",
    "For demonstration, we'll create a sample dataset of customer reviews with binary sentiments (positive=1, negative=0). In a real scenario, you would load your dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "data = {\n",
    "    'review': [\n",
    "        'The product is amazing and works perfectly!',\n",
    "        'Terrible experience, the item broke after one use.',\n",
    "        'I love this product, highly recommend it!',\n",
    "        'Very disappointing, poor quality and bad service.',\n",
    "        'Fantastic purchase, exceeded my expectations!',\n",
    "        'Not worth the money, stopped working quickly.',\n",
    "        'Great customer service and fast delivery!',\n",
    "        'Horrible product, complete waste of money.',\n",
    "        'Really happy with my purchase, will buy again.',\n",
    "        'The worst experience Iâ€™ve ever had with a product.'\n",
    "    ],\n",
    "    'sentiment': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing\n",
    "\n",
    "We preprocess the reviews by converting to lowercase, removing special characters, tokenizing, removing stopwords, and lemmatizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "df[['review', 'cleaned_review']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Vectorization\n",
    "\n",
    "We convert the cleaned text into numerical features using TF-IDF vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Transform reviews to TF-IDF features\n",
    "X = tfidf.fit_transform(df['cleaned_review'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training set shape: {X_train.shape}')\n",
    "print(f'Testing set shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Logistic Regression Model\n",
    "\n",
    "We train a Logistic Regression model on the TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model\n",
    "\n",
    "We evaluate the model using a classification report and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predict Sentiment for New Reviews\n",
    "\n",
    "We demonstrate how to predict sentiment for new reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example new reviews\n",
    "new_reviews = [\n",
    "    'This product is fantastic and works great!',\n",
    "    'Awful experience, never buying again.'\n",
    "]\n",
    "\n",
    "# Preprocess new reviews\n",
    "new_reviews_cleaned = [preprocess_text(review) for review in new_reviews]\n",
    "\n",
    "# Transform using TF-IDF\n",
    "new_reviews_tfidf = tfidf.transform(new_reviews_cleaned)\n",
    "\n",
    "# Predict sentiment\n",
    "predictions = model.predict(new_reviews_tfidf)\n",
    "\n",
    "# Display results\n",
    "for review, sentiment in zip(new_reviews, predictions):\n",
    "    print(f'Review: {review}')\n",
    "    print(f'Predicted Sentiment: {\"Positive\" if sentiment == 1 else \"Negative\"}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This notebook demonstrated sentiment analysis using TF-IDF vectorization and Logistic Regression. The preprocessing steps cleaned the text data, the TF-IDF vectorizer converted text to numerical features, and the Logistic Regression model classified sentiments. The model was evaluated using standard metrics, and we showed how to predict sentiments for new reviews."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
